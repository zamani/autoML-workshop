{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hdAnqA3sdcR"
      },
      "source": [
        "# Deep Neural Learning and Bayesian Optimization of Hyperparameters\n",
        "\n",
        "## Mohammad Ali Zamani\n",
        "### Senior Machine Learning Scientist\n",
        " [zamani.ai](https://zamani.ai)\n",
        "\n",
        "\n",
        "---\n",
        " \n",
        "some parts taken from: https://pytorch.org/tutorials/\n",
        "\n",
        "more about AutoML: https://www.automl.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbAgPoF5KnTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b385b061-823d-44b0-9b82-384c9ba5a044"
      },
      "source": [
        "!pip install hpbandster\n",
        "!wget -nc \"https://github.com/YoongiKim/CIFAR-10-images/archive/master.zip\"\n",
        "!unzip -n master.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: hpbandster in /usr/local/lib/python3.8/dist-packages (0.7.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from hpbandster) (1.21.6)\n",
            "Requirement already satisfied: ConfigSpace in /usr/local/lib/python3.8/dist-packages (from hpbandster) (0.6.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.8/dist-packages (from hpbandster) (0.12.2)\n",
            "Requirement already satisfied: serpent in /usr/local/lib/python3.8/dist-packages (from hpbandster) (1.41)\n",
            "Requirement already satisfied: netifaces in /usr/local/lib/python3.8/dist-packages (from hpbandster) (0.11.0)\n",
            "Requirement already satisfied: Pyro4 in /usr/local/lib/python3.8/dist-packages (from hpbandster) (4.82)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from hpbandster) (1.7.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from ConfigSpace->hpbandster) (3.0.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from ConfigSpace->hpbandster) (0.29.32)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from ConfigSpace->hpbandster) (4.4.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels->hpbandster) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.8/dist-packages (from statsmodels->hpbandster) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2022.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels->hpbandster) (1.15.0)\n",
            "File ‘master.zip’ already there; not retrieving.\n",
            "\n",
            "Archive:  master.zip\n",
            "d7d05618061fe37d830fb0419063d113c575ccbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HydxfH6RxRqV"
      },
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBpB60-rUy4K"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "from torch.utils.data import Dataset \n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def build_cifar_path_label(set_type, training_sample_num):\n",
        "    dataset_path = 'CIFAR-10-images-master'\n",
        "    label_name = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                  'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    images_path = []\n",
        "    label_num = []\n",
        "\n",
        "    if set_type == 'train':\n",
        "        if training_sample_num == -1:\n",
        "            sample_num = 4500.\n",
        "        else:\n",
        "            sample_num = training_sample_num / 10\n",
        "        for i in range(len(label_name)):\n",
        "            for j in range(int(sample_num)):\n",
        "                images_path.append(os.path.join(dataset_path, 'train', label_name[i], str(j).zfill(4) + '.jpg'))\n",
        "                label_num.append(i)\n",
        "    \n",
        "    elif set_type == 'val':\n",
        "        for i in range(len(label_name)):\n",
        "            for j in range(4500,5000):\n",
        "                images_path.append(os.path.join(dataset_path, 'train', label_name[i], str(j).zfill(4) + '.jpg'))\n",
        "                label_num.append(i)\n",
        "\n",
        "    elif set_type == 'test':\n",
        "        for i in range(len(label_name)):\n",
        "            for j in range(1000):\n",
        "                images_path.append(os.path.join(dataset_path, 'test', label_name[i], str(j).zfill(4) + '.jpg'))\n",
        "                label_num.append(i)\n",
        "\n",
        "    return images_path, label_num\n",
        "\n",
        "class MyDataSet(Dataset):\n",
        "    def __init__(self, set_type, training_sample_num, data_transforms):\n",
        "        super(MyDataSet, self).__init__()\n",
        "    \t\n",
        "        images_path, labels = build_cifar_path_label(set_type, training_sample_num)\n",
        "\n",
        "        images = np.zeros((len(labels), 32, 32, 3), dtype=np.uint8)\n",
        "        for i in tqdm(range(len(images_path))):\n",
        "            images[i, :, :, :] = io.imread(images_path[i])\n",
        "           \n",
        "        self.input = images\n",
        "        self.label = np.asarray(labels)\n",
        "        self.transform = data_transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.label)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.transform(transforms.ToPILImage()(self.input[idx])), self.label[idx]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_7Ljz8blwna"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "def my_loss(output, target):\n",
        "    loss = torch.mean((output - target)**2)\n",
        "    return loss\n",
        "\n",
        "class Optimization():\n",
        "    def __init__(self, args, loss,  train_loader, val_loader, test_loader):\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.test_loader = test_loader\n",
        "        device = args.device\n",
        "        self.args = args\n",
        "        self.model = CNN(args).to(device)\n",
        "        \n",
        "        print(\"number of trainable parameter = \", count_parameters(self.model))\n",
        "        \n",
        "        if args.optimizer == 'Adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=args.rate)\n",
        "        elif args.optimizer == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=args.rate, momentum=args.sgd_momentum)\n",
        "\n",
        "        self.scheduler = StepLR(self.optimizer, step_size=args.lr_decay_step)\n",
        "\n",
        "        self.loss = loss\n",
        "        self.device = device\n",
        "\n",
        "    def train(self):\n",
        "        batch_counter = 0.0\n",
        "        total_loss = 0.0\n",
        "        self.model.train()\n",
        "        for iter, data in enumerate(self.train_loader):\n",
        "            \n",
        "            inputs, labels = data \n",
        "\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "\n",
        "            self.model.zero_grad()\n",
        "            outputs = self.model(inputs)\n",
        "            loss = self.loss(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_counter += 1\n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        loss_value = total_loss / batch_counter\n",
        "        return loss_value\n",
        "\n",
        "    def val_eval(self):\n",
        "        batch_counter = 0.0\n",
        "        total_loss = 0.0\n",
        "        self.model.eval()\n",
        "        for iter, data in enumerate(self.val_loader):\n",
        "            inputs, labels = data\n",
        "            \n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            \n",
        "            # for evaluating the network, we disable the gradient calculation with the no_grad function\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.loss(outputs, labels)\n",
        "\n",
        "            batch_counter += 1\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        loss_value = total_loss / batch_counter\n",
        "        return loss_value\n",
        "\n",
        "    def test_eval(self, graph=False):\n",
        "        total= 0.0\n",
        "        correct = 0\n",
        "        class_correct = list(0. for i in range(10))\n",
        "        class_total = list(0. for i in range(10))\n",
        "        self.model.eval()\n",
        "\n",
        "        for iter, data in enumerate(self.test_loader):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "           \n",
        "            # for evaluating the network, we disable the gradient calculation with the no_grad function\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(inputs)\n",
        "                _ , predicted = torch.max(outputs, 1)\n",
        "                result = (predicted == labels)\n",
        "                total += labels.size(0)\n",
        "                correct += result.sum().item()\n",
        "\n",
        "                c = result.squeeze()\n",
        "                for i in range(labels.shape[0]):\n",
        "                    label = labels[i]\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "         \n",
        "        test_acc = correct / total\n",
        "        \n",
        "        print()\n",
        "        for i in range(10): \n",
        "            print('%s: %2d%%,' % (classes[i], 100 * class_correct[i] / class_total[i]), end =\" \")\n",
        "        print()\n",
        "        \n",
        "        return test_acc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49PnXvz0l_E6"
      },
      "source": [
        "import copy\n",
        "\n",
        "def main(args, train_loader, val_loader, test_loader):\n",
        "    device = torch.device(args.device)\n",
        "    best_val_error = np.inf\n",
        "\n",
        "    if args.loss == 'NLL':\n",
        "        loss_function = nn.NLLLoss(reduction='mean')\n",
        "    elif args.loss == 'CE':\n",
        "        loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
        "        nn.CrossEntropyLoss\n",
        "\n",
        "    optimization = Optimization(args, loss_function, train_loader, val_loader, test_loader)\n",
        "\n",
        "    train_loss_records = []\n",
        "    val_loss_records = []\n",
        "    test_loss_records = []\n",
        "\n",
        "    print(\"loading training, val and test set completed!\")\n",
        "    mistake_counter = 0  # mistakes counter for validation loss\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        train_loss = optimization.train()\n",
        "        train_loss_records.append(train_loss)\n",
        "        optimization.scheduler.step()\n",
        "\n",
        "        val_loss = optimization.val_eval()\n",
        "        val_loss_records.append(val_loss)\n",
        "\n",
        "        test_loss = optimization.test_eval()\n",
        "        test_loss_records.append(test_loss)\n",
        "\n",
        "        if epoch > 1:\n",
        "            if val_loss_records[-1] > val_loss_records[-2]:\n",
        "                mistake_counter += 1\n",
        "\n",
        "        if val_loss < best_val_error:\n",
        "            best_results = {\n",
        "                'epoch': epoch + 1,\n",
        "                'state_dict': copy.deepcopy(optimization.model.state_dict()),\n",
        "                'model': optimization.model,\n",
        "                'best_val_error': val_loss,\n",
        "                'best_test_error': test_loss,\n",
        "                'optimizer': copy.deepcopy(optimization.optimizer),\n",
        "                'args': args\n",
        "            }\n",
        "            best_val_error = val_loss\n",
        "        print(\n",
        "            '[Epoch: %3d/%3d] LR: %0.8f  Train loss: %.4f,    Val loss: %.4f,   Test Acc: %.4f'\n",
        "            % (epoch + 1, args.epochs, optimization.scheduler.get_lr()[0], train_loss_records[epoch], val_loss_records[epoch],\n",
        "               test_loss_records[epoch]))\n",
        "        \n",
        "        if mistake_counter >= args.tol or epoch == args.epochs - 1:\n",
        "            print('Training is terminated')\n",
        "            break\n",
        "    return test_loss, val_loss"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt0_CEYBmA67"
      },
      "source": [
        "from typing import NamedTuple\n",
        "class Args(NamedTuple):\n",
        "    rate: float  # learning rate\n",
        "    lr_decay_step: int  # learning rate decay\n",
        "    batch_size: int  # minibatch size\n",
        "    epochs: int  # maximum training epochs\n",
        "    sample_num: int  # number of sample to be loaded\n",
        "    tol: int  # tolerance for the validation error increment\n",
        "    device: str  # cuda or cpu\n",
        "    loss: str  # loss function     \n",
        "    optimizer: str # optimizer method\n",
        "    sgd_momentum: float #\n",
        "\n",
        "    dropout: float  # the probability for dropout \n",
        "    fc1: int # 1st hidden layer's units\n",
        "    fc2: int\n",
        "    cout1: int\n",
        "    cout2: int\n",
        "    cout3: int\n",
        "    cout4: int\n",
        "    ks1: int\n",
        "    # TODO: add more layers if necessary"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yxJMH_XljXQ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, args.cout1, args.ks1, 1, int(np.ceil((args.ks1-1)/2)))\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(args.cout1, args.cout2, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(args.cout2, args.cout3, 3, 1, 1 )\n",
        "        self.conv4 = nn.Conv2d(args.cout3, args.cout4, 3, 1, 1)\n",
        "        self.fc1 = nn.Linear(2*2*args.cout4, args.fc1)\n",
        "        self.fc2 = nn.Linear(args.fc1, args.fc2)\n",
        "        self.fc3 = nn.Linear(args.fc2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P067Q5CfqqOE"
      },
      "source": [
        "# for hyperparameter optimization\n",
        "import ConfigSpace as CS\n",
        "import ConfigSpace.hyperparameters as CSH\n",
        "from hpbandster.core.worker import Worker\n",
        "import hpbandster.core.nameserver as hpns\n",
        "import hpbandster.core.result as hpres\n",
        "from hpbandster.optimizers import BOHB\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "class PyTorchWorker(Worker):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        \n",
        "        self.batch_size = 128\n",
        "        self.sample_num = 4500\n",
        "\n",
        "        self.data_transforms = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.RandomRotation(5),\n",
        "                transforms.ColorJitter(\n",
        "                    brightness=0.1,\n",
        "                    contrast=0.1,\n",
        "                    saturation=0.1,\n",
        "                    hue=0.1),\n",
        "                transforms.RandomCrop((32, 32)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.CenterCrop((32, 32)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "            'test': transforms.Compose([\n",
        "                transforms.CenterCrop((32, 32)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ]),\n",
        "        }\n",
        "\n",
        "        training_set = MyDataSet(set_type='train', training_sample_num=self.sample_num, data_transforms=self.data_transforms['train'])\n",
        "        val_set = MyDataSet(set_type='val', training_sample_num=None, data_transforms=self.data_transforms['val'])\n",
        "        test_set = MyDataSet(set_type='test', training_sample_num=None, data_transforms=self.data_transforms['test'])\n",
        "\n",
        "        self.train_loader = DataLoader(training_set, batch_size=self.batch_size, num_workers=8, shuffle=True, drop_last=False)\n",
        "        self.val_loader = DataLoader(test_set, batch_size=self.batch_size, num_workers=8, shuffle=False, drop_last=True)\n",
        "        self.test_loader = DataLoader(test_set, batch_size=self.batch_size, num_workers=8, shuffle=False, drop_last=True)\n",
        "\n",
        "    def compute(self, config, budget, working_directory, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        testing the configuration\n",
        "        \"\"\"\n",
        "        print(\"Selected HyperParameters to test: \")\n",
        "        print(config)\n",
        "        new_args = Args(\n",
        "                        rate=config['lr'],\n",
        "                        lr_decay_step=100,\n",
        "                        batch_size=self.batch_size,\n",
        "                        epochs=int(budget),\n",
        "                        sample_num = self.sample_num,\n",
        "                        tol=100,\n",
        "                        loss='CE',\n",
        "                        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "\n",
        "                        optimizer= 'Adam',\n",
        "                        sgd_momentum= 0.0,\n",
        "                        dropout= config['dropout'],\n",
        "                        fc1=config['fc1'], # \n",
        "                        fc2=config['fc2'],\n",
        "                        cout1=config['cout1'],\n",
        "                        cout2=config['cout2'],\n",
        "                        cout3=config['cout3'],\n",
        "                        cout4=config['cout4'],\n",
        "                        ks1=config['ks1']\n",
        "                        # TODO2 add the additional parameters from Args class here\n",
        "                        )\n",
        "\n",
        "        test_acc, val_loss = main(new_args, self.train_loader, self.val_loader, self.test_loader)\n",
        "        return ({\n",
        "            'loss': val_loss,  # remember: HpBandSter always minimizes!\n",
        "            'info': {'test accuracy': test_acc,\n",
        "                     }\n",
        "        })\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_configspace():\n",
        "        \"\"\"\n",
        "            It builds the configuration space with the needed hyperparameters\n",
        "            :return: ConfigurationsSpace-Object\n",
        "            \"\"\"\n",
        "        cs = CS.ConfigurationSpace()\n",
        "\n",
        "        # TODO3: add a proper condition here\n",
        " \n",
        "        lr = CSH.UniformFloatHyperparameter('lr', lower=1e-4, upper=1e-1, default_value='1e-2', log=True)\n",
        "        cs.add_hyperparameters([lr])\n",
        "\n",
        "        # Type 4 condition: Integer\n",
        "        fc1 = CSH.UniformIntegerHyperparameter('fc1', lower=50, upper=200, default_value=100, log=False)\n",
        "        fc2 = CSH.UniformIntegerHyperparameter('fc2', lower=20, upper=80, default_value=50, log=False)\n",
        "\n",
        "        cs.add_hyperparameters([fc1, fc2])\n",
        "\n",
        "        cout1 = CSH.UniformIntegerHyperparameter('cout1', lower=8, upper=32, default_value=16, log=False)\n",
        "        cout2 = CSH.UniformIntegerHyperparameter('cout2', lower=8, upper=32, default_value=16, log=False)\n",
        "        cout3 = CSH.UniformIntegerHyperparameter('cout3', lower=8, upper=32, default_value=16, log=False)\n",
        "        cout4 = CSH.UniformIntegerHyperparameter('cout4', lower=8, upper=32, default_value=16, log=False)\n",
        "        \n",
        "        cs.add_hyperparameters([cout1, cout2, cout3, cout4])\n",
        "\n",
        "        dropout = CSH.UniformFloatHyperparameter('dropout', lower=0.0, upper=0.9, default_value=0.1, log=False)\n",
        "        cs.add_hyperparameters([dropout])\n",
        "\n",
        "        ks1 = CSH.UniformIntegerHyperparameter('ks1', lower=3, upper=6, default_value=3, log=False)\n",
        "        cs.add_hyperparameters([ks1])\n",
        "\n",
        "        return cs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DnqKcuzqjlw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec25790f-ff58-4a2b-b0c5-4f33331d4f14"
      },
      "source": [
        "# TO record a backup from the old hyperparamter searches\n",
        "def backup_jsons(curDir):\n",
        "    for fname in ('results', 'configs'):\n",
        "        if os.path.exists(curDir + os.path.sep + fname + '.json'):\n",
        "            counter = 1\n",
        "            while os.path.exists(curDir + os.path.sep + fname + '_' + str(counter) + '.json'):\n",
        "                counter += 1\n",
        "            os.rename(curDir + os.path.sep + fname + '.json', curDir + os.path.sep + fname + '_' + str(counter) + '.json')\n",
        "\n",
        "\n",
        "args_min_budget = 1 # Minimum number of epochs for training.\n",
        "args_max_budget = 9 # Maximum number of epochs for training.\n",
        "args_n_iterations = 1 # Number of iterations performed by the optimizer\n",
        "args_worker = False # Flag to turn this into a worker process\n",
        "args_run_id = '' # A unique run id for this optimization run. An easy option is to use the job id of the clusters scheduler.\n",
        "args_nic_name = 'lo' # Which network interface to use for communication.\n",
        "args_shared_directory = '.' # A directory that is accessible for all processes, e.g. a NFS share.\n",
        "args_eta = 3 # eta\n",
        "\n",
        "# Every process has to lookup the hostname\n",
        "host = hpns.nic_name_to_host(args_nic_name)\n",
        "\n",
        "\n",
        "if args_worker:\n",
        "    import time\n",
        "    time.sleep(1)   # short artificial delay to make sure the nameserver is already running\n",
        "    w = PyTorchWorker(run_id=args_run_id, host=host, timeout=120)\n",
        "    w.load_nameserver_credentials(working_directory=args_shared_directory)\n",
        "    w.run(background=False)\n",
        "    exit(0)\n",
        "\n",
        "\n",
        "# This example shows how to log live results. This is most useful\n",
        "# for really long runs, where intermediate results could already be\n",
        "# interesting. The core.result submodule contains the functionality to\n",
        "# read the two generated files (results.json and configs.json) and\n",
        "# create a Result object.\n",
        "\n",
        "#backup_jsons(args_shared_directory)\n",
        "result_logger = hpres.json_result_logger(directory=args_shared_directory, overwrite=True)\n",
        "\n",
        "# Start a nameserver:\n",
        "NS = hpns.NameServer(run_id=args_run_id, host=host, port=0, working_directory=args_shared_directory)\n",
        "ns_host, ns_port = NS.start()\n",
        "\n",
        "# Start local worker\n",
        "w = PyTorchWorker(run_id=args_run_id, host=host, nameserver=ns_host, nameserver_port=ns_port, timeout=120)\n",
        "w.run(background=True)\n",
        "\n",
        "# Run an optimizer\n",
        "bohb = BOHB(  configspace = PyTorchWorker.get_configspace(),\n",
        "                        run_id = args_run_id,\n",
        "                        eta = args_eta,\n",
        "                        host=host,\n",
        "                        nameserver=ns_host,\n",
        "                        nameserver_port=ns_port,\n",
        "                        result_logger=result_logger,\n",
        "                        min_budget=args_min_budget, \n",
        "                        max_budget=args_max_budget,\n",
        "                        \n",
        "                        # in case of expecting better result change the following \n",
        "                        num_samples = 32, # 1st decrease\n",
        "                        top_n_percent=25, # 2nd increase \n",
        "                        bandwidth_factor=10, # 3rd increase or/and\n",
        "                        min_bandwidth=1e-3, # 3rd increase\n",
        "            \n",
        "               )\n",
        "res = bohb.run(n_iterations=args_n_iterations)\n",
        "\n",
        "# store results\n",
        "with open(os.path.join(args_shared_directory, 'results.pkl'), 'wb') as fh:\n",
        "    pickle.dump(res, fh)\n",
        "\n",
        "# shutdown\n",
        "bohb.shutdown(shutdown_workers=True)\n",
        "NS.shutdown()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4500/4500 [00:01<00:00, 2665.24it/s]\n",
            "100%|██████████| 5000/5000 [00:02<00:00, 2352.42it/s]\n",
            "100%|██████████| 10000/10000 [00:07<00:00, 1400.46it/s]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected HyperParameters to test: \n",
            "{'cout1': 14, 'cout2': 18, 'cout3': 23, 'cout4': 13, 'dropout': 0.62176899822779, 'fc1': 117, 'fc2': 74, 'ks1': 4, 'lr': 0.002647862065496716}\n",
            "number of trainable parameter =  25108\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 30%, car: 43%, bird:  0%, cat:  0%, deer:  0%, dog: 22%, frog: 83%, horse: 22%, ship: 29%, truck: 24%, \n",
            "[Epoch:   1/  1] LR: 0.00264786  Train loss: 2.1571,    Val loss: 2.0370,   Test Acc: 0.2564\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 12, 'cout2': 11, 'cout3': 20, 'cout4': 16, 'dropout': 0.7225418640916027, 'fc1': 63, 'fc2': 77, 'ks1': 6, 'lr': 0.00034299661310539234}\n",
            "number of trainable parameter =  17206\n",
            "loading training, val and test set completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:381: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "plane:  0%, car:  0%, bird:  0%, cat: 85%, deer:  0%, dog:  0%, frog:  0%, horse: 19%, ship:  0%, truck:  0%, \n",
            "[Epoch:   1/  1] LR: 0.00034300  Train loss: 2.3025,    Val loss: 2.2969,   Test Acc: 0.1063\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 23, 'cout2': 28, 'cout3': 28, 'cout4': 12, 'dropout': 0.16770267183187637, 'fc1': 119, 'fc2': 34, 'ks1': 6, 'lr': 0.03114342262343905}\n",
            "number of trainable parameter =  28712\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane:  0%, car:  0%, bird:  0%, cat: 100%, deer:  0%, dog:  0%, frog:  0%, horse:  0%, ship:  0%, truck:  0%, \n",
            "[Epoch:   1/  1] LR: 0.03114342  Train loss: 2.6176,    Val loss: 2.3087,   Test Acc: 0.1002\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 29, 'cout2': 26, 'cout3': 11, 'cout4': 11, 'dropout': 0.09685790596616882, 'fc1': 180, 'fc2': 74, 'ks1': 3, 'lr': 0.014761977215336444}\n",
            "number of trainable parameter =  33553\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 36%, car:  2%, bird: 15%, cat:  2%, deer:  1%, dog: 25%, frog: 52%, horse: 10%, ship: 14%, truck: 59%, \n",
            "[Epoch:   1/  1] LR: 0.01476198  Train loss: 2.2239,    Val loss: 2.1216,   Test Acc: 0.2206\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 19, 'cout2': 27, 'cout3': 26, 'cout4': 17, 'dropout': 0.817710696451992, 'fc1': 90, 'fc2': 25, 'ks1': 4, 'lr': 0.016256345251302096}\n",
            "number of trainable parameter =  24659\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane:  0%, car: 100%, bird:  0%, cat:  0%, deer:  0%, dog:  0%, frog:  0%, horse:  0%, ship:  0%, truck:  0%, \n",
            "[Epoch:   1/  1] LR: 0.01625635  Train loss: 2.3133,    Val loss: 2.3029,   Test Acc: 0.1002\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 20, 'cout2': 31, 'cout3': 31, 'cout4': 18, 'dropout': 0.5962584010900566, 'fc1': 138, 'fc2': 33, 'ks1': 6, 'lr': 0.017060248788672114}\n",
            "number of trainable parameter =  36512\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 53%, car:  0%, bird:  4%, cat:  0%, deer:  2%, dog: 20%, frog: 64%, horse: 15%, ship:  3%, truck: 45%, \n",
            "[Epoch:   1/  1] LR: 0.01706025  Train loss: 2.2257,    Val loss: 2.1107,   Test Acc: 0.2099\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 32, 'cout2': 26, 'cout3': 12, 'cout4': 24, 'dropout': 0.8184494615974771, 'fc1': 91, 'fc2': 56, 'ks1': 5, 'lr': 0.00018056956647915045}\n",
            "number of trainable parameter =  29931\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 96%, car:  0%, bird:  0%, cat:  2%, deer:  0%, dog:  8%, frog:  0%, horse:  0%, ship:  0%, truck:  3%, \n",
            "[Epoch:   1/  1] LR: 0.00018057  Train loss: 2.2985,    Val loss: 2.2885,   Test Acc: 0.1105\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 14, 'cout2': 15, 'cout3': 15, 'cout4': 19, 'dropout': 0.4856774515553027, 'fc1': 165, 'fc2': 65, 'ks1': 6, 'lr': 0.005541125747539662}\n",
            "number of trainable parameter =  32210\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 46%, car: 15%, bird:  3%, cat:  0%, deer: 57%, dog: 26%, frog:  3%, horse: 13%, ship: 40%, truck: 46%, \n",
            "[Epoch:   1/  1] LR: 0.00554113  Train loss: 2.1518,    Val loss: 2.0549,   Test Acc: 0.2530\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 25, 'cout2': 30, 'cout3': 27, 'cout4': 12, 'dropout': 0.5753482328852954, 'fc1': 155, 'fc2': 22, 'ks1': 4, 'lr': 0.001081143463399004}\n",
            "number of trainable parameter =  29507\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 27%, car:  0%, bird:  0%, cat:  2%, deer:  5%, dog: 57%, frog:  1%, horse: 36%, ship: 21%, truck: 64%, \n",
            "[Epoch:   1/  1] LR: 0.00108114  Train loss: 2.2386,    Val loss: 2.0896,   Test Acc: 0.2155\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 14, 'cout2': 18, 'cout3': 23, 'cout4': 13, 'dropout': 0.62176899822779, 'fc1': 117, 'fc2': 74, 'ks1': 4, 'lr': 0.002647862065496716}\n",
            "number of trainable parameter =  25108\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 80%, car:  3%, bird:  0%, cat: 51%, deer:  0%, dog: 11%, frog:  0%, horse:  0%, ship:  6%, truck: 34%, \n",
            "[Epoch:   1/  3] LR: 0.00264786  Train loss: 2.2326,    Val loss: 2.1463,   Test Acc: 0.1877\n",
            "\n",
            "plane: 37%, car:  7%, bird:  0%, cat: 14%, deer: 10%, dog: 19%, frog: 67%, horse: 12%, ship: 33%, truck: 75%, \n",
            "[Epoch:   2/  3] LR: 0.00264786  Train loss: 2.0197,    Val loss: 1.9656,   Test Acc: 0.2772\n",
            "\n",
            "plane: 29%, car: 33%, bird:  0%, cat:  0%, deer: 15%, dog: 41%, frog: 64%, horse: 40%, ship: 68%, truck: 38%, \n",
            "[Epoch:   3/  3] LR: 0.00264786  Train loss: 1.8734,    Val loss: 1.7848,   Test Acc: 0.3333\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 14, 'cout2': 15, 'cout3': 15, 'cout4': 19, 'dropout': 0.4856774515553027, 'fc1': 165, 'fc2': 65, 'ks1': 6, 'lr': 0.005541125747539662}\n",
            "number of trainable parameter =  32210\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane:  8%, car:  1%, bird:  2%, cat: 35%, deer: 63%, dog:  0%, frog:  0%, horse: 18%, ship: 53%, truck: 43%, \n",
            "[Epoch:   1/  3] LR: 0.00554113  Train loss: 2.2029,    Val loss: 2.0520,   Test Acc: 0.2278\n",
            "\n",
            "plane: 37%, car: 39%, bird:  1%, cat:  3%, deer:  0%, dog: 14%, frog: 79%, horse: 41%, ship:  0%, truck: 13%, \n",
            "[Epoch:   2/  3] LR: 0.00554113  Train loss: 1.9946,    Val loss: 2.0207,   Test Acc: 0.2290\n",
            "\n",
            "plane: 22%, car: 39%, bird:  0%, cat:  0%, deer:  2%, dog: 20%, frog: 73%, horse: 56%, ship: 14%, truck: 26%, \n",
            "[Epoch:   3/  3] LR: 0.00554113  Train loss: 1.9074,    Val loss: 2.0445,   Test Acc: 0.2574\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 25, 'cout2': 30, 'cout3': 27, 'cout4': 12, 'dropout': 0.5753482328852954, 'fc1': 155, 'fc2': 22, 'ks1': 4, 'lr': 0.001081143463399004}\n",
            "number of trainable parameter =  29507\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane: 22%, car: 30%, bird:  0%, cat:  5%, deer: 81%, dog:  0%, frog:  0%, horse:  0%, ship:  0%, truck: 14%, \n",
            "[Epoch:   1/  3] LR: 0.00108114  Train loss: 2.2550,    Val loss: 2.2320,   Test Acc: 0.1541\n",
            "\n",
            "plane: 36%, car: 30%, bird:  1%, cat:  9%, deer:  0%, dog:  0%, frog: 61%, horse: 18%, ship: 50%, truck: 45%, \n",
            "[Epoch:   2/  3] LR: 0.00108114  Train loss: 2.0964,    Val loss: 2.0388,   Test Acc: 0.2520\n",
            "\n",
            "plane: 26%, car: 12%, bird:  2%, cat:  3%, deer:  2%, dog: 35%, frog: 69%, horse: 43%, ship: 45%, truck: 34%, \n",
            "[Epoch:   3/  3] LR: 0.00108114  Train loss: 1.9936,    Val loss: 1.9547,   Test Acc: 0.2762\n",
            "Training is terminated\n",
            "Selected HyperParameters to test: \n",
            "{'cout1': 14, 'cout2': 18, 'cout3': 23, 'cout4': 13, 'dropout': 0.62176899822779, 'fc1': 117, 'fc2': 74, 'ks1': 4, 'lr': 0.002647862065496716}\n",
            "number of trainable parameter =  25108\n",
            "loading training, val and test set completed!\n",
            "\n",
            "plane:  1%, car:  3%, bird:  0%, cat:  0%, deer:  0%, dog: 74%, frog: 22%, horse: 19%, ship: 71%, truck: 24%, \n",
            "[Epoch:   1/  9] LR: 0.00264786  Train loss: 2.1900,    Val loss: 2.0527,   Test Acc: 0.2177\n",
            "\n",
            "plane: 52%, car: 34%, bird:  0%, cat:  0%, deer:  0%, dog: 30%, frog: 68%, horse: 48%, ship: 25%, truck: 60%, \n",
            "[Epoch:   2/  9] LR: 0.00264786  Train loss: 1.9593,    Val loss: 1.8196,   Test Acc: 0.3200\n",
            "\n",
            "plane: 38%, car: 63%, bird:  1%, cat:  3%, deer: 11%, dog: 33%, frog: 50%, horse: 60%, ship: 31%, truck: 48%, \n",
            "[Epoch:   3/  9] LR: 0.00264786  Train loss: 1.8144,    Val loss: 1.7490,   Test Acc: 0.3422\n",
            "\n",
            "plane: 54%, car: 19%, bird:  2%, cat:  5%, deer:  4%, dog: 61%, frog: 52%, horse: 50%, ship: 38%, truck: 63%, \n",
            "[Epoch:   4/  9] LR: 0.00264786  Train loss: 1.7385,    Val loss: 1.7162,   Test Acc: 0.3513\n",
            "\n",
            "plane: 48%, car: 44%, bird:  5%, cat: 11%, deer: 13%, dog: 36%, frog: 47%, horse: 67%, ship: 47%, truck: 58%, \n",
            "[Epoch:   5/  9] LR: 0.00264786  Train loss: 1.6688,    Val loss: 1.6413,   Test Acc: 0.3803\n",
            "\n",
            "plane: 53%, car: 75%, bird: 10%, cat: 17%, deer: 26%, dog: 20%, frog: 65%, horse: 51%, ship: 37%, truck: 38%, \n",
            "[Epoch:   6/  9] LR: 0.00264786  Train loss: 1.6510,    Val loss: 1.6156,   Test Acc: 0.3954\n",
            "\n",
            "plane: 62%, car: 38%, bird: 32%, cat: 10%, deer: 32%, dog: 34%, frog: 40%, horse: 60%, ship: 38%, truck: 59%, \n",
            "[Epoch:   7/  9] LR: 0.00264786  Train loss: 1.5587,    Val loss: 1.5878,   Test Acc: 0.4105\n",
            "\n",
            "plane: 52%, car: 62%, bird: 30%, cat: 34%, deer: 29%, dog: 32%, frog: 38%, horse: 60%, ship: 46%, truck: 48%, \n",
            "[Epoch:   8/  9] LR: 0.00264786  Train loss: 1.5070,    Val loss: 1.5338,   Test Acc: 0.4342\n",
            "\n",
            "plane: 44%, car: 60%, bird: 13%, cat: 47%, deer: 21%, dog: 22%, frog: 45%, horse: 44%, ship: 47%, truck: 71%, \n",
            "[Epoch:   9/  9] LR: 0.00264786  Train loss: 1.4825,    Val loss: 1.5824,   Test Acc: 0.4197\n",
            "Training is terminated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D__lD5b4qiAt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "6f3345b1-2525-4e13-9065-dd1e70df6c7d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import hpbandster.core.result as hpres\n",
        "import hpbandster.visualization as hpvis\n",
        "\n",
        "# load the example run from the log files\n",
        "result = hpres.logged_results_to_HBS_result('.')\n",
        "\n",
        "# get all executed runs\n",
        "all_runs = result.get_all_runs()\n",
        "\n",
        "# get the 'dict' that translates config ids to the actual configurations\n",
        "id2conf = result.get_id2config_mapping()\n",
        "\n",
        "\n",
        "# Here is how you get he incumbent (best configuration)\n",
        "inc_id = result.get_incumbent_id()\n",
        "\n",
        "# let's grab the run on the highest budget\n",
        "inc_runs = result.get_runs_by_id(inc_id)\n",
        "inc_run = inc_runs[-1]\n",
        "\n",
        "\n",
        "# We have access to all information: the config, the loss observed during\n",
        "#optimization, and all the additional information\n",
        "inc_loss = inc_run.loss\n",
        "inc_config = id2conf[inc_id]['config']\n",
        "inc_test_loss = inc_run.info['test accuracy']\n",
        "\n",
        "print('Best found configuration:')\n",
        "print(inc_config)\n",
        "print('It achieved validation loss of %f and test accuracy of %f .'%(inc_loss, inc_test_loss))\n",
        "\n",
        "\n",
        "# Let's plot the observed losses grouped by budget,\n",
        "hpvis.losses_over_time(all_runs)\n",
        "\n",
        "# and the number of finished runs.\n",
        "hpvis.finished_runs_over_time(all_runs)\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best found configuration:\n",
            "{'cout1': 14, 'cout2': 18, 'cout3': 23, 'cout4': 13, 'dropout': 0.62176899822779, 'fc1': 117, 'fc2': 74, 'ks1': 4, 'lr': 0.002647862065496716}\n",
            "It achieved validation loss of 1.582353 and test accuracy of 0.419671 .\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}